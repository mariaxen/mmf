wandb_version: 1

_metadata:
  desc: null
  value: 'ContainerMetadata(ref_type=typing.Any, object_type=None, optional=True,
    key=None, flags={''struct'': True}, flags_root=False, resolver_cache=defaultdict(<class
    ''dict''>, {}), key_type=typing.Any, element_type=typing.Any)'
_parent:
  desc: null
  value: null
_content:
  desc: null
  value:
    config_version: '1.0'
    training: '{''trainer'': ''mmf'', ''seed'': 21284305, ''experiment_name'': ''mmf_video_audio'',
      ''max_updates'': 5, ''max_epochs'': 5, ''log_interval'': 1, ''logger_level'':
      ''info'', ''log_format'': ''simple'', ''log_detailed_config'': False, ''should_not_log'':
      False, ''colored_logs'': True, ''tensorboard'': False, ''cudnn_benchmark'':
      False, ''wandb'': {''enabled'': True, ''entity'': None, ''project'': ''mmf'',
      ''name'': ''mmf_video_audio'', ''log_checkpoint'': False}, ''batch_size'': 64,
      ''batch_size_per_device'': None, ''update_frequency'': 1, ''num_workers'': 2,
      ''fast_read'': False, ''dataset_size_proportional_sampling'': True, ''pin_memory'':
      False, ''persistent_workers'': True, ''checkpoint_interval'': 285, ''evaluation_interval'':
      2, ''clip_gradients'': False, ''clip_norm_mode'': ''all'', ''early_stop'': {''enabled'':
      False, ''patience'': 2, ''criteria'': ''viva/logit_bce'', ''minimize'': True},
      ''lr_scheduler'': False, ''lr_steps'': [], ''lr_ratio'': 0.1, ''use_warmup'':
      False, ''warmup_factor'': 0.2, ''warmup_iterations'': 340, ''device'': ''cuda'',
      ''local_rank'': None, ''verbose_dump'': False, ''find_unused_parameters'': True,
      ''evaluate_metrics'': True, ''detect_anomaly'': False, ''fp16'': True, ''callbacks'':
      [], ''exit_on_nan_losses'': True}'
    trainer: '{''type'': ''lightning'', ''params'': {''gpus'': 8, ''num_nodes'': 1,
      ''precision'': 32, ''deterministic'': False, ''benchmark'': False, ''max_steps'':
      22000, ''max_epochs'': 10, ''gradient_clip_val'': 0.0, ''num_sanity_val_steps'':
      0, ''enable_checkpointing'': True, ''accumulate_grad_batches'': 1, ''val_check_interval'':
      5, ''log_every_n_steps'': 10, ''logger'': False, ''limit_val_batches'': 1.0,
      ''enable_progress_bar'': False, ''resume_from_checkpoint'': None}}'
    evaluation: '{''metrics'': [''accuracy'', ''specificity'', ''sensitivity'', ''npv'',
      ''ppv'', ''confusion_matrix''], ''use_cpu'': True, ''predict'': True, ''predict_file_format'':
      ''csv'', ''reporter'': {''type'': ''file'', ''params'': {}}}'
    model_config: '{''viva_model'': {''losses'': [{''type'': ''logit_bce''}], ''video_encoder'':
      {''type'': ''timesformer'', ''params'': {''num_output_features'': 1, ''pool_type'':
      ''avg'', ''out_dim'': 2048, ''three_d'': True}}, ''audio_encoder'': {''type'':
      ''resnet18_audio'', ''params'': {''embedding_dim'': 512, ''num_output_features'':
      1, ''pool_type'': ''avg'', ''out_dim'': 2048, ''three_d'': False}}, ''tabular_transforms'':
      {''in_dim'': 2, ''out_dim'': 12}, ''text_encoder'': {''type'': ''transformer''},
      ''interaction_layer'': {''input_dim'': 2060, ''hidden_dim'': 256, ''output_dim'':
      512}, ''classifier'': {''type'': ''mlp'', ''num_labels'': 2, ''params'': {''in_dim'':
      12, ''out_dim'': 2}}, ''dropout'': 0.15, ''model'': ''viva_model''}}'
    dataset_config: '{''viva'': {''data_dir'': ''/home/maria/.cache/torch/mmf/data/datasets'',
      ''prediction_threshold'': 0.5, ''annotations'': {''train'': [''viva/defaults/Viva/Viva_v1_train.csv''],
      ''val'': [''viva/defaults/Viva/Viva_v1_test.csv''], ''test'': [''viva/defaults/Viva/Viva_v1_test.csv'']},
      ''videos'': {''train'': [''viva/defaults/alphabets_256''], ''val'': [''viva/defaults/alphabets_256''],
      ''test'': [''viva/defaults/alphabets_256'']}, ''classes_file'': ''viva/defaults/Viva/Viva_v1_classes.txt'',
      ''processors'': {''text_processor'': {''type'': ''bert_tokenizer'', ''params'':
      {''tokenizer_config'': {''type'': ''bert-base-uncased'', ''params'': {''do_lower_case'':
      True}}, ''mask_probability'': 0, ''max_seq_length'': 128}}, ''tabular_processor'':
      {''type'': ''tabular_standardize'', ''params'': {''eps'': 1e-10}}, ''audio_processor'':
      {''type'': ''torchvision_transforms'', ''params'': {''transforms'': [{''type'':
      ''truncate_or_pad'', ''params'': {''output_size'': 1000}}, ''MelSpectrogram'',
      ''ToPILImage'', {''type'': ''Resize'', ''params'': {''size'': [224, 224]}},
      ''ToTensor'']}}, ''video_train_processor'': {''type'': ''video_transforms'',
      ''params'': {''transforms'': [''permute_and_rescale'', {''type'': ''Resize'',
      ''params'': {''size'': [256, 256]}}, ''RandomHorizontalFlip'', ''ColorJitter'',
      {''type'': ''Normalize'', ''params'': {''mean'': [0.43216, 0.394666, 0.37645],
      ''std'': [0.22803, 0.22145, 0.216989]}}, {''type'': ''RandomCrop'', ''params'':
      {''size'': [224, 224]}}]}}, ''video_test_processor'': {''type'': ''video_transforms'',
      ''params'': {''transforms'': [''permute_and_rescale'', {''type'': ''Resize'',
      ''params'': {''size'': [256, 256]}}, {''type'': ''Normalize'', ''params'': {''mean'':
      [0.43216, 0.394666, 0.37645], ''std'': [0.22803, 0.22145, 0.216989]}}, {''type'':
      ''RandomCrop'', ''params'': {''size'': [224, 224]}}]}}}}}'
    datasets: viva
    model: viva_model
    config: projects/viva/direct.yaml
    run_type: train_val
    optimizer: '{''allow_unused_parameters'': False, ''enable_state_sharding'': False,
      ''type'': ''adam_w'', ''params'': {''lr'': 0.0001, ''eps'': 1e-08}}'
    scheduler: '{''type'': ''warmup_cosine'', ''params'': {''num_warmup_steps'': 1,
      ''num_training_steps'': 5}}'
    env: '{''cache_dir'': ''/home/maria/.cache/torch/mmf'', ''dataset_zoo'': ''configs/zoo/datasets.yaml'',
      ''model_zoo'': ''configs/zoo/models.yaml'', ''data_dir'': ''/home/maria/.cache/torch/mmf/data'',
      ''save_dir'': ''./save'', ''log_dir'': '''', ''report_dir'': '''', ''tensorboard_logdir'':
      '''', ''wandb_logdir'': '''', ''user_dir'': ''''}'
    distributed: '{''init_method'': ''tcp://localhost:10143'', ''rank'': 0, ''port'':
      -1, ''backend'': ''nccl'', ''world_size'': 8, ''no_spawn'': False}'
    checkpoint: '{''resume'': False, ''resume_file'': None, ''resume_best'': False,
      ''resume_pretrained'': False, ''resume_zoo'': None, ''zoo_config_override'':
      False, ''pretrained_state_mapping'': {}, ''max_to_keep'': -1, ''save_git_details'':
      True, ''reset'': {''all'': False, ''optimizer'': False, ''counts'': False, ''fp16_scaler'':
      False}}'
    multitasking: '{''enabled'': False, ''type'': ''size_proportional'', ''params'':
      {}}'
    start_rank: '0'
    device_id: '0'
_flags_cache:
  desc: null
  value:
    struct: true
    readonly: null
    allow_objects: null
_wandb:
  desc: null
  value:
    python_version: 3.7.12
    cli_version: 0.15.2
    framework: huggingface
    huggingface_version: 4.10.1
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1687211850.667723
    t:
      1:
      - 1
      - 5
      - 9
      - 11
      - 29
      - 40
      - 41
      - 49
      - 51
      - 53
      - 55
      2:
      - 1
      - 5
      - 9
      - 11
      - 29
      - 40
      - 41
      - 49
      - 51
      - 53
      - 55
      3:
      - 7
      - 13
      - 16
      - 23
      4: 3.7.12
      5: 0.15.2
      6: 4.10.1
      8:
      - 5
    m:
    - 1: trainer/global_step
      6:
      - 3
    - 1: train/learning_rate
      5: 1
      6:
      - 1
    - 1: train/viva/logit_bce
      5: 1
      6:
      - 1
    - 1: train/total_loss
      5: 1
      6:
      - 1
    - 1: train/viva/accuracy
      5: 1
      6:
      - 1
    - 1: train/viva/confusion_matrix/actual_admitted
      5: 1
      6:
      - 1
    - 1: train/viva/confusion_matrix/actual_discharged
      5: 1
      6:
      - 1
    - 1: train/viva/confusion_matrix/false_negatives
      5: 1
      6:
      - 1
    - 1: train/viva/confusion_matrix/false_positives
      5: 1
      6:
      - 1
    - 1: train/viva/confusion_matrix/predicted_admitted
      5: 1
      6:
      - 1
    - 1: train/viva/confusion_matrix/predicted_discharged
      5: 1
      6:
      - 1
    - 1: train/viva/confusion_matrix/true_negatives
      5: 1
      6:
      - 1
    - 1: train/viva/confusion_matrix/true_positives
      5: 1
      6:
      - 1
    - 1: train/viva/npv
      5: 1
      6:
      - 1
    - 1: train/viva/ppv
      5: 1
      6:
      - 1
    - 1: train/viva/sensitivity
      5: 1
      6:
      - 1
    - 1: train/viva/specificity
      5: 1
      6:
      - 1
    - 1: val/viva/logit_bce
      5: 1
      6:
      - 1
    - 1: val/total_loss
      5: 1
      6:
      - 1
    - 1: val/viva/accuracy
      5: 1
      6:
      - 1
    - 1: val/viva/confusion_matrix/actual_admitted
      5: 1
      6:
      - 1
    - 1: val/viva/confusion_matrix/actual_discharged
      5: 1
      6:
      - 1
    - 1: val/viva/confusion_matrix/false_negatives
      5: 1
      6:
      - 1
    - 1: val/viva/confusion_matrix/false_positives
      5: 1
      6:
      - 1
    - 1: val/viva/confusion_matrix/predicted_admitted
      5: 1
      6:
      - 1
    - 1: val/viva/confusion_matrix/predicted_discharged
      5: 1
      6:
      - 1
    - 1: val/viva/confusion_matrix/true_negatives
      5: 1
      6:
      - 1
    - 1: val/viva/confusion_matrix/true_positives
      5: 1
      6:
      - 1
    - 1: val/viva/npv
      5: 1
      6:
      - 1
    - 1: val/viva/ppv
      5: 1
      6:
      - 1
    - 1: val/viva/sensitivity
      5: 1
      6:
      - 1
    - 1: val/viva/specificity
      5: 1
      6:
      - 1
